#####PARAMETERS#####
dropOut_alpha=NaN
preTrain_learningRate=0.1
dropOut_beta=NaN
epoch=1000
fineTune_learningRate=1.5
CD_k=1
classifier=logisticRegression
label_number=1
dropOut_standard=0.6
hidden_layers=20,12
preTrain_randomSeed=343432
mode=test
0.0076788207125566945	0.0	
0.008908265954589687	0.0	
0.9582955058234662	0.0	
0.033969381141614886	0.0	
0.007438278777301394	0.0	
0.00742404681238563	0.0	
0.00742506292288328	0.0	
0.007419345967490718	0.0	
0.007418976545646761	0.0	
0.9975311957097559	1.0	
0.007457087342242382	0.0	
0.00835223758010697	0.0	
0.999143373433495	0.0	
0.00816963472874794	1.0	
0.5888695779263536	0.0	
0.007531990727106374	0.0	
0.007498078502553861	0.0	
0.007498078502553861	0.0	
0.00744869057909801	0.0	
0.9992282281658909	1.0	
0.008908265954589687	0.0	
0.9582955058234662	0.0	
0.009380378967849465	0.0	
0.00742506292288328	0.0	
0.009380378967849465	0.0	
0.00755298373005161	0.0	
0.007476415653607525	0.0	
0.8785705503014845	1.0	
0.9996644438665581	1.0	
0.00742404681238563	0.0	
0.008361795406620836	0.0	
0.007829337626314365	0.0	
0.9961060057126658	1.0	
0.0076788207125566945	0.0	
0.007563599186108997	1.0	
0.007419345967490718	0.0	
0.8882863961761598	1.0	
0.007418976545646761	0.0	
0.007457087342242382	0.0	
0.00835223758010697	0.0	
0.00755298373005161	0.0	
0.0076788207125566945	0.0	
0.007563599186108997	1.0	
0.012265314995862742	0.0	
0.015765696267203616	0.0	
0.012265314995862742	0.0	
0.007829337626314365	0.0	
0.9966039739375264	1.0	
0.007476415653607525	0.0	
0.08810005417794983	0.0	
0.00744869057909801	0.0	
0.00744869057909801	0.0	
0.008908265954589687	0.0	
0.9582955058234662	0.0	
0.009380378967849465	0.0	
0.00755298373005161	0.0	
0.007476415653607525	1.0	
0.08810005417794983	0.0	
0.007457087342242382	0.0	
0.08810005417794983	0.0	
0.9995313346912307	1.0	
0.007563599186108997	1.0	
0.033969381141614886	0.0	
0.007438278777301394	0.0	
0.015765696267203616	0.0	
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Accuracy=0.8461538461538461
TP=8
FP=5
FN=5
TN=47
