#####PARAMETERS#####
dropOut_alpha=NaN
preTrain_learningRate=0.1
dropOut_beta=NaN
epoch=1000
fineTune_learningRate=1.5
CD_k=1
classifier=logisticRegression
label_number=1
dropOut_standard=0.5
hidden_layers=40,20
preTrain_randomSeed=33
mode=test
0.007735021342300279	0.0	
0.040110413443913445	0.0	
0.9943304945303826	0.0	
0.076704032070315	0.0	
0.006253363561215996	0.0	
0.0059846187883153615	0.0	
0.005979179547936303	0.0	
0.005909691475444648	0.0	
0.0059032568696984885	0.0	
0.9863995958906046	1.0	
0.006709307676586894	0.0	
0.00983675135160083	0.0	
0.9993886095332702	0.0	
0.013969030635782559	1.0	
0.21031266884121033	0.0	
0.006211181978902019	0.0	
0.006329578135462017	0.0	
0.006329578135462017	0.0	
0.00693883225615684	0.0	
0.9971653265523939	1.0	
0.040110413443913445	0.0	
0.9943304945303826	0.0	
0.015480081624085552	0.0	
0.005979179547936303	0.0	
0.015480081624085552	0.0	
0.006736589772694065	0.0	
0.006759887848414504	0.0	
0.41299011022877646	1.0	
0.9966522897800338	1.0	
0.0059846187883153615	0.0	
0.011648415736864225	0.0	
0.009417436503465573	0.0	
0.9891246694995943	1.0	
0.007735021342300279	0.0	
0.006892590596837308	1.0	
0.005909691475444648	0.0	
0.2230068139272401	1.0	
0.0059032568696984885	0.0	
0.006709307676586894	0.0	
0.00983675135160083	0.0	
0.006736589772694065	0.0	
0.007735021342300279	0.0	
0.006892590596837308	1.0	
0.007814106983670542	0.0	
0.023148558004870853	0.0	
0.007814106983670542	0.0	
0.009417436503465573	0.0	
0.940820217637149	1.0	
0.006759887848414504	0.0	
0.10024420648154253	0.0	
0.00693883225615684	0.0	
0.00693883225615684	0.0	
0.040110413443913445	0.0	
0.9943304945303826	0.0	
0.015480081624085552	0.0	
0.006736589772694065	0.0	
0.006759887848414504	1.0	
0.10024420648154253	0.0	
0.006709307676586894	0.0	
0.10024420648154253	0.0	
0.9994751912964035	1.0	
0.006892590596837308	1.0	
0.076704032070315	0.0	
0.006253363561215996	0.0	
0.023148558004870853	0.0	
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Accuracy=0.8307692307692308
TP=6
FP=4
FN=7
TN=48
