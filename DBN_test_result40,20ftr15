#####PARAMETERS#####
dropOut_alpha=NaN
preTrain_learningRate=0.1
dropOut_beta=NaN
epoch=1000
fineTune_learningRate=15
CD_k=1
classifier=logisticRegression
label_number=1
dropOut_standard=0.5
hidden_layers=40,20
preTrain_randomSeed=5555
mode=test
0.0044433812220911	0.0	
0.004410175330894147	0.0	
0.008007770915210871	0.0	
0.005727507086643452	0.0	
0.004382041437696597	0.0	
0.004373651190309635	0.0	
0.004366056658787141	0.0	
0.004363730321827609	0.0	
0.004363732279608123	0.0	
0.08562055056252411	1.0	
0.004430625518780245	0.0	
0.004514220323033587	0.0	
0.6182620279971169	0.0	
0.00437424411782324	1.0	
0.03215264661240057	0.0	
0.004367565174700497	0.0	
0.004365135542584025	0.0	
0.004365135542584025	0.0	
0.004368657163482604	0.0	
0.5025170855469757	1.0	
0.004410175330894147	0.0	
0.008007770915210871	0.0	
0.004426888160538105	0.0	
0.004366056658787141	0.0	
0.004426888160538105	0.0	
0.004403612938530959	0.0	
0.004364385142769711	0.0	
0.00587043246671218	1.0	
0.9799243102883427	1.0	
0.004373651190309635	0.0	
0.005161447896650439	0.0	
0.00446324563036373	0.0	
0.18404873019526483	1.0	
0.0044433812220911	0.0	
0.004373020656331631	1.0	
0.004363730321827609	0.0	
0.008528303137083217	1.0	
0.004363732279608123	0.0	
0.004430625518780245	0.0	
0.004514220323033587	0.0	
0.004403612938530959	0.0	
0.0044433812220911	0.0	
0.004373020656331631	1.0	
0.0049038172870309055	0.0	
0.006631535713649629	0.0	
0.0049038172870309055	0.0	
0.00446324563036373	0.0	
0.9933886975050605	1.0	
0.004364385142769711	0.0	
0.005486815026389146	0.0	
0.004368657163482604	0.0	
0.004368657163482604	0.0	
0.004410175330894147	0.0	
0.008007770915210871	0.0	
0.004426888160538105	0.0	
0.004403612938530959	0.0	
0.004364385142769711	1.0	
0.005486815026389146	0.0	
0.004430625518780245	0.0	
0.005486815026389146	0.0	
0.9998488983775217	1.0	
0.004373020656331631	1.0	
0.005727507086643452	0.0	
0.004382041437696597	0.0	
0.006631535713649629	0.0	
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Accuracy=0.8461538461538461
TP=4
FP=1
FN=9
TN=51
