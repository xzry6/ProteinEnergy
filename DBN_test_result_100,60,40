#####PARAMETERS#####
dropOut_alpha=NaN
preTrain_learningRate=0.1
dropOut_beta=NaN
epoch=1000
fineTune_learningRate=1.5
CD_k=1
classifier=logisticRegression
label_number=1
dropOut_standard=0.5
hidden_layers=100,60,40
preTrain_randomSeed=32553532
mode=test
9.306445774094368E-5	0.0	
7.323603352227986E-5	0.0	
4.15214230568506E-4	0.0	
0.05246909807079965	0.0	
4.329113459905102E-5	0.0	
2.709181233169448E-5	0.0	
2.8827559066138768E-5	0.0	
2.686349414553778E-5	0.0	
2.6463490607434036E-5	0.0	
0.9677309220261362	1.0	
1.8992300312118727E-4	0.0	
4.092901478914009E-4	0.0	
0.9892201183669216	0.0	
1.3519436856250524E-4	1.0	
0.10455421250589422	0.0	
2.6750862356105042E-5	0.0	
2.9877262864137316E-5	0.0	
2.9877262864137316E-5	0.0	
3.039655073367471E-5	0.0	
0.9878319165798986	1.0	
7.323603352227986E-5	0.0	
4.15214230568506E-4	0.0	
3.540240387149806E-5	0.0	
2.8827559066138768E-5	0.0	
3.540240387149806E-5	0.0	
2.8163375070523154E-5	0.0	
2.7946983497259615E-5	0.0	
0.050699432543376714	1.0	
0.9635009217731761	1.0	
2.709181233169448E-5	0.0	
0.01043806855823019	0.0	
0.06333618228186609	0.0	
0.98744932216504	1.0	
9.306445774094368E-5	0.0	
5.3906619934074394E-5	1.0	
2.686349414553778E-5	0.0	
0.003612995370827162	1.0	
2.6463490607434036E-5	0.0	
1.8992300312118727E-4	0.0	
4.092901478914009E-4	0.0	
2.8163375070523154E-5	0.0	
9.306445774094368E-5	0.0	
5.3906619934074394E-5	1.0	
2.7358118290210436E-5	0.0	
0.0019774444909216845	0.0	
2.7358118290210436E-5	0.0	
0.06333618228186609	0.0	
0.9472583248147116	1.0	
2.7946983497259615E-5	0.0	
7.601078001928614E-5	0.0	
3.039655073367471E-5	0.0	
3.039655073367471E-5	0.0	
7.323603352227986E-5	0.0	
4.15214230568506E-4	0.0	
3.540240387149806E-5	0.0	
2.8163375070523154E-5	0.0	
2.7946983497259615E-5	1.0	
7.601078001928614E-5	0.0	
1.8992300312118727E-4	0.0	
7.601078001928614E-5	0.0	
0.9874900356630526	1.0	
5.3906619934074394E-5	1.0	
0.05246909807079965	0.0	
4.329113459905102E-5	0.0	
0.0019774444909216845	0.0	
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Accuracy=0.8769230769230769
TP=6
FP=1
FN=7
TN=51
